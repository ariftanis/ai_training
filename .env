# Model Configuration
MODEL_NAME=unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit
MAX_SEQ_LENGTH=8192

# LoRA Configuration
LORA_RANK=128
LORA_ALPHA=32
LORA_DROPOUT=0.05

# Training Configuration
NUM_EPOCHS=5
BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=8
WARMUP_STEPS=50
LEARNING_RATE=2e-4

# Dataset Processing
DATASET_NUM_PROC=2

# Model Output Configuration
OUTPUT_DIR=outputs
SAVE_STRATEGY=epoch

# GGUF Export Configuration
GGUF_OUTPUT_NAME=sancaktepe-model.gguf
GGUF_QUANTIZATION=q8_0

# Valid quantization options: q4_k_m, q5_k_m, q8_0, f16, f32
# q4_k_m: Good balance of size/speed/quality (recommended for most use cases)
# q5_k_m: Higher quality than q4_k_m, larger file size
# q8_0: Near original quality, larger file size than q4/q5
# f16: Full precision, largest file size